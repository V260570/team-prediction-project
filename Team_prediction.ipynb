{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction of victory based on data from the first 5 minutes of the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/features.zip', index_col='match_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['first_blood_time', 'first_blood_team', 'first_blood_player1',\n",
       "       'first_blood_player2', 'radiant_bottle_time', 'radiant_courier_time',\n",
       "       'radiant_flying_courier_time', 'radiant_first_ward_time',\n",
       "       'dire_bottle_time', 'dire_courier_time', 'dire_flying_courier_time',\n",
       "       'dire_first_ward_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df[df.columns[:-6]]\n",
    "# features with missing values:\n",
    "features.columns[features.count() < features.count().max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.fillna(value=0)\n",
    "X = features.values\n",
    "y = df['radiant_win']\n",
    "kf = KFold(shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 trees. Time elapsed: 0:05:29.813855\n",
      "Total time elapsed: 0:18:13.872373\n",
      "\n",
      "Quality estimates:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{10: 0.6637173759568478,\n",
       " 20: 0.681722162516617,\n",
       " 30: 0.688614862673372,\n",
       " 40: 0.6934400126999827}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GradientBoosting\n",
    "\n",
    "scores = {}\n",
    "initial_time = datetime.datetime.now()\n",
    "for n in range(10, 50, 10):\n",
    "    if n == 30:\n",
    "        start_time = datetime.datetime.now()\n",
    "    clf = GradientBoostingClassifier(n_estimators=n, random_state=0)\n",
    "    scores[n] = cross_val_score(clf, X, y, cv=kf, scoring='roc_auc').mean()\n",
    "    if n == 30:\n",
    "        print('30 trees. Time elapsed:', datetime.datetime.now() - start_time)\n",
    "\n",
    "print('Total time elapsed:', datetime.datetime.now() - initial_time)\n",
    "print('\\nQuality estimates:')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For features 'first_blood_time' and 'first_blood_team' omissions can mean that the \"first blood\" event didn't happen in the first 5 minutes.\n",
    "\n",
    "2. Column 'radiant_win' contains target variable.\n",
    "\n",
    "3. Cross-validation for gradient boosting with 30 trees took over 5 min at quality 0.6886.\n",
    "\n",
    "4. When the number of trees increased to 40, the quality increased slightly. To speed up learning when increasing the number of trees, you can either use subset of objects, or decrease the depth of the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "# cross-validation with all features\n",
    "\n",
    "X_lr = StandardScaler().fit_transform(features)\n",
    "scores = {}\n",
    "score_time = []\n",
    "for n in np.geomspace(1e-4, 1e+2, 121):\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf = LogisticRegression(C=n, random_state=0)\n",
    "    scores[n] = cross_val_score(clf, X_lr, y, cv=kf, scoring='roc_auc').mean()\n",
    "    score_time.append(datetime.datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C = 0.004466835921509635, score = 0.7162726606305722, max running time = 0:00:07.502003'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best regularization parameter C, maximum computation time\n",
    "\n",
    "C = max(scores, key=scores.get)\n",
    "f'C = {C}, score = {scores[C]}, max running time = {max(score_time)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C = 0.004466835921509635, score = 0.7163328498343842'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validation without categorical features\n",
    "\n",
    "less_features = features.copy()\n",
    "less_features.pop('lobby_type')\n",
    "[less_features.pop(label) for label in features.columns if 'hero' in label]\n",
    "\n",
    "X_less = StandardScaler().fit_transform(less_features)\n",
    "scores_less = {}\n",
    "for n in np.geomspace(1e-4, 1e+2, 121):\n",
    "    clf = LogisticRegression(C=n, random_state=0)\n",
    "    scores_less[n] = cross_val_score(clf, X_less, y, cv=kf, scoring='roc_auc').mean()\n",
    "\n",
    "C = max(scores_less, key=scores_less.get)\n",
    "f'C = {C}, score = {scores_less[C]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'number of hero IDs: 108, maximum hero id: 112'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heros_id = np.unique(features[[label for label in features.columns if 'hero' in label]].values)\n",
    "f'number of hero IDs: {heros_id.size}, maximum hero id: {heros_id.max()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating \"bag of words\" features\n",
    "\n",
    "X_pick = np.zeros((features.shape[0], heros_id.max()))\n",
    "\n",
    "for i, match_id in enumerate(features.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, features.at[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, features.at[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C = 0.01, score = 0.751779840685833'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample with \"bag of words\"\n",
    "\n",
    "data_with_words = pd.concat([less_features, pd.DataFrame(X_pick, index=less_features.index)], axis=1)\n",
    "X_w = StandardScaler().fit_transform(data_with_words)\n",
    "scores_w = {}\n",
    "for n in np.logspace(-2, 2, 20):\n",
    "    clf = LogisticRegression(C=n, random_state=0)\n",
    "    scores_w[n] = cross_val_score(clf, X_w, y, cv=kf, scoring='roc_auc').mean()\n",
    "C = max(scores_w, key=scores_w.get)\n",
    "f'C = {C}, score = {scores_w[C]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "\n",
    "df_test = pd.read_csv('data/features_test.zip', index_col='match_id')\n",
    "df_test = df_test.fillna(0)\n",
    "\n",
    "X_pick_test = np.zeros((df_test.shape[0], heros_id.max()))\n",
    "for i, match_id in enumerate(df_test.index):\n",
    "    for p in range(5):\n",
    "        X_pick_test[i, df_test.at[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick_test[i, df_test.at[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n",
    "df_test.pop('lobby_type')\n",
    "df_test = df_test.drop([label for label in df_test.columns if 'hero' in label], axis=1)\n",
    "\n",
    "df_test_words = pd.concat([df_test, pd.DataFrame(X_pick_test, index=df_test.index)], axis=1)\n",
    "\n",
    "X_test_w = StandardScaler().fit_transform(df_test_words)\n",
    "\n",
    "clf_test = LogisticRegression(C=0.01)\n",
    "clf_test.fit(X_w, y)\n",
    "pred = clf_test.predict_proba(X_test_w)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.008721474723098676, 0.9963305890721884)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.min(), pred.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The quality of the logistic regression over all initial features is 0.716, it's a bit more than the gradient boost quality value. The absence of a difference with gradient boosting indicates a linear relationship between features and target variable. Logistic regression is ten times faster.\n",
    "\n",
    "2. Removing categorical features had almost no effect on the quality of the logistic regression. The new quality is 0.71633. Most likely, these signs do not affect the prediction result in any way.\n",
    "\n",
    "3. There are 108 different Hero IDs in the game, maximum number of identifiers 112.\n",
    "\n",
    "4. Quality in the sample when adding a \"bag of words\" for heroes is higher, than on the original sample, possibly because the merged matrix is sparse.\n",
    "\n",
    "5. Minimum and maximum value of the forecast on the test set: 0.0087 0.9963"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
